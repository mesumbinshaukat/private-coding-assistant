# ü§ù Contributing to Autonomous AI Agent

Welcome to the Autonomous AI Agent project! We're excited that you want to contribute. This guide will help you get started with contributing to this open-source project.

## üéØ Project Overview

This project is a production-ready, autonomous AI agent designed for coding tasks. It features:

- ü§ñ Autonomous planning and execution
- üîç Deep web searching capabilities
- üß† Self-training and improvement
- üíª Desktop integration
- ‚òÅÔ∏è Serverless deployment on Vercel

## üöÄ Quick Start for Contributors

### 1. Fork and Clone

```bash
# Fork the repository on GitHub, then:
git clone https://github.com/YOUR_USERNAME/autonomous-ai-agent.git
cd autonomous-ai-agent

# Add upstream remote
git remote add upstream https://github.com/ORIGINAL_OWNER/autonomous-ai-agent.git
```

### 2. Set Up Development Environment

```bash
# Run the setup script
python scripts/setup.py

# Or manual setup:
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate
pip install -r requirements.txt
pip install -r requirements-dev.txt  # Development dependencies
```

### 3. Create a Feature Branch

```bash
git checkout -b feature/your-feature-name
# or
git checkout -b fix/issue-description
```

## üìã Types of Contributions

We welcome various types of contributions:

### üêõ Bug Reports
- Clear description of the issue
- Steps to reproduce
- Expected vs actual behavior
- Environment details (OS, Python version, etc.)

### üí° Feature Requests
- Clear use case description
- Proposed implementation approach
- Consideration of alternatives

### üîß Code Contributions
- Bug fixes
- New features
- Performance improvements
- Documentation updates
- Test improvements

### üìö Documentation
- API documentation
- Tutorials and guides
- Code comments
- Architecture documentation

## üõ†Ô∏è Development Guidelines

### Code Style

We follow PEP 8 with some modifications:

```python
# Use black for formatting
black .

# Use flake8 for linting
flake8 .

# Use mypy for type checking
mypy api/
```

### Project Structure

```
autonomous-ai-agent/
‚îú‚îÄ‚îÄ api/                    # FastAPI backend
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ index.py           # Main API entry point
‚îÇ   ‚îú‚îÄ‚îÄ agent_core.py      # Core agent logic
‚îÇ   ‚îî‚îÄ‚îÄ utils/             # Utility modules
‚îú‚îÄ‚îÄ desktop-app/           # Electron desktop app
‚îú‚îÄ‚îÄ docs/                  # Documentation
‚îú‚îÄ‚îÄ examples/              # Usage examples
‚îú‚îÄ‚îÄ scripts/               # Setup and utility scripts
‚îú‚îÄ‚îÄ tests/                 # Test suite
‚îú‚îÄ‚îÄ requirements.txt       # Python dependencies
‚îî‚îÄ‚îÄ vercel.json           # Deployment configuration
```

### Coding Standards

#### Python Code

```python
# Good: Clear function names and docstrings
async def generate_code_with_reasoning(
    prompt: str, 
    language: str = "python", 
    context: Optional[str] = None
) -> Dict[str, Any]:
    """
    Generate code with step-by-step reasoning.
    
    Args:
        prompt: The code generation prompt
        language: Target programming language
        context: Optional context for generation
        
    Returns:
        Dictionary containing generated code and reasoning steps
    """
    # Implementation here
    pass

# Good: Type hints and error handling
try:
    result = await self.llm.generate(prompt)
    return {"code": result.code, "explanation": result.explanation}
except Exception as e:
    logger.error(f"Code generation failed: {e}")
    raise HTTPException(status_code=500, detail="Generation failed")
```

#### TypeScript/JavaScript (Desktop App)

```javascript
// Good: Clear interfaces and documentation
interface AIResponse {
  code: string;
  explanation: string;
  confidence: number;
}

/**
 * Send a request to the AI agent API
 * @param endpoint - API endpoint to call
 * @param data - Request payload
 * @returns Promise resolving to AI response
 */
async function sendAIRequest(endpoint: string, data: any): Promise<AIResponse> {
  try {
    const response = await fetch(`${API_BASE}${endpoint}`, {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${API_TOKEN}`,
        'Content-Type': 'application/json'
      },
      body: JSON.stringify(data)
    });
    
    if (!response.ok) {
      throw new Error(`API request failed: ${response.statusText}`);
    }
    
    return await response.json();
  } catch (error) {
    console.error('AI request failed:', error);
    throw error;
  }
}
```

### Testing

#### Writing Tests

```python
# tests/test_agent_core.py
import pytest
from unittest.mock import Mock, AsyncMock
from api.agent_core import AutonomousAgent

@pytest.mark.asyncio
class TestAutonomousAgent:
    """Test suite for AutonomousAgent core functionality"""
    
    async def test_code_generation_success(self):
        """Test successful code generation"""
        agent = AutonomousAgent()
        await agent.initialize()
        
        result = await agent.generate_code(
            "Write a function to calculate fibonacci numbers",
            "python"
        )
        
        assert "code" in result
        assert "explanation" in result
        assert "confidence" in result
        assert result["confidence"] > 0.0
    
    async def test_code_generation_error_handling(self):
        """Test error handling in code generation"""
        agent = AutonomousAgent()
        # Mock failure scenario
        agent.llm = Mock()
        agent.llm.generate = AsyncMock(side_effect=Exception("Model error"))
        
        with pytest.raises(Exception):
            await agent.generate_code("invalid prompt", "unknown_language")
```

#### Running Tests

```bash
# Run all tests
python -m pytest

# Run with coverage
python -m pytest --cov=api --cov-report=html

# Run specific test file
python -m pytest tests/test_agent_core.py -v

# Run specific test
python -m pytest tests/test_agent_core.py::TestAutonomousAgent::test_code_generation_success -v
```

### Documentation

#### Docstring Format

```python
def complex_function(param1: str, param2: int, param3: Optional[bool] = None) -> Dict[str, Any]:
    """
    Brief description of what the function does.
    
    Longer description if needed, explaining the algorithm,
    use cases, or important implementation details.
    
    Args:
        param1: Description of parameter 1
        param2: Description of parameter 2
        param3: Optional parameter with default value
        
    Returns:
        Dictionary containing:
            - key1 (str): Description of key1
            - key2 (int): Description of key2
            
    Raises:
        ValueError: When param2 is negative
        HTTPException: When external API call fails
        
    Example:
        >>> result = complex_function("test", 42, True)
        >>> print(result["key1"])
        "processed_test"
    """
```

#### API Documentation

```python
from fastapi import FastAPI
from pydantic import BaseModel, Field

class CodeRequest(BaseModel):
    """Request model for code generation endpoint"""
    
    prompt: str = Field(
        ..., 
        description="The code generation prompt",
        example="Write a Python function for binary search"
    )
    language: str = Field(
        "python",
        description="Target programming language",
        example="python"
    )
    context: Optional[str] = Field(
        None,
        description="Optional context for generation",
        example="This is for a data structures class"
    )

@app.post("/generate", response_model=CodeResponse)
async def generate_code_endpoint(request: CodeRequest):
    """
    Generate code based on a natural language prompt.
    
    This endpoint uses the autonomous AI agent to generate code
    with step-by-step reasoning and explanation.
    """
    # Implementation
```

## üß™ Testing Your Changes

### 1. Run the Test Suite

```bash
# Full test suite
python -m pytest tests/ -v

# Quick smoke tests
python -m pytest tests/test_api.py::test_health_check -v
```

### 2. Manual Testing

```bash
# Start development server
python -m uvicorn api.index:app --reload

# Test in another terminal
curl -X POST http://localhost:8000/generate \
  -H "Authorization: Bearer autonomous-ai-agent-2024" \
  -H "Content-Type: application/json" \
  -d '{"prompt": "Write a hello world function", "language": "python"}'
```

### 3. Integration Testing

```bash
# Test desktop app integration
cd desktop-app/electron-app
npm test

# Test deployment configuration
vercel dev
```

## üìù Submitting Changes

### 1. Commit Message Format

We use [Conventional Commits](https://www.conventionalcommits.org/):

```bash
# Feature commits
git commit -m "feat: add web search integration with DuckDuckGo"
git commit -m "feat(api): implement self-training endpoint"

# Bug fix commits
git commit -m "fix: resolve memory leak in model loading"
git commit -m "fix(desktop): handle API connection errors gracefully"

# Documentation commits
git commit -m "docs: add API endpoint examples"
git commit -m "docs(setup): improve installation instructions"

# Other types: chore, refactor, test, style, perf
git commit -m "test: add unit tests for memory manager"
git commit -m "refactor: extract common utility functions"
```

### 2. Pull Request Process

1. **Ensure Tests Pass**
   ```bash
   python -m pytest
   python -m flake8
   python -m black --check .
   ```

2. **Update Documentation**
   - Update docstrings for new functions
   - Add examples to relevant docs
   - Update API documentation if needed

3. **Create Pull Request**
   - Clear title and description
   - Reference related issues
   - Include testing instructions
   - Add screenshots for UI changes

4. **Pull Request Template**
   ```markdown
   ## Description
   Brief description of changes
   
   ## Type of Change
   - [ ] Bug fix
   - [ ] New feature
   - [ ] Breaking change
   - [ ] Documentation update
   
   ## Testing
   - [ ] Tests pass locally
   - [ ] Added tests for new features
   - [ ] Manual testing completed
   
   ## Checklist
   - [ ] Code follows style guidelines
   - [ ] Self-review completed
   - [ ] Documentation updated
   - [ ] No breaking changes (or clearly documented)
   ```

### 3. Code Review Process

#### For Reviewers
- Check code quality and style
- Verify tests are adequate
- Test functionality manually
- Review documentation updates
- Consider performance implications

#### For Contributors
- Respond to feedback promptly
- Make requested changes
- Keep commits atomic and focused
- Rebase if needed to keep history clean

## üöÄ Advanced Contributions

### 1. Adding New Agent Capabilities

```python
# api/utils/new_capability.py
class NewCapability:
    """Add a new capability to the agent"""
    
    async def execute(self, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """Execute the new capability"""
        # Implementation
        pass

# api/agent_core.py
class AutonomousAgent:
    def __init__(self):
        # Add to agent initialization
        self.new_capability = NewCapability()
    
    async def handle_new_capability_request(self, request):
        """Handle requests for new capability"""
        return await self.new_capability.execute(request)
```

### 2. Extending the Desktop App

```javascript
// desktop-app/electron-app/renderer/js/new-feature.js
class NewFeature {
  constructor(aiClient) {
    this.aiClient = aiClient;
  }
  
  async execute(params) {
    try {
      const response = await this.aiClient.request('/new-endpoint', params);
      return this.processResponse(response);
    } catch (error) {
      console.error('New feature failed:', error);
      throw error;
    }
  }
  
  processResponse(response) {
    // Process and display response
    return response;
  }
}
```

### 3. Adding New Training Methods

```python
# api/utils/training_manager.py
class CustomTrainingMethod:
    """Implement a new training approach"""
    
    async def train(self, model, dataset, config):
        """Custom training implementation"""
        # Your training logic here
        pass
        
    def evaluate(self, model, test_data):
        """Evaluate the trained model"""
        # Your evaluation logic here
        pass
```

## üîç Debugging and Development Tips

### 1. Development Environment

```bash
# Enable debug mode
export DEBUG=true
export LOG_LEVEL=DEBUG

# Use development model for faster iteration
export MODEL_NAME=distilgpt2  # Smaller, faster model
```

### 2. Debugging Tools

```python
# Add breakpoints
import pdb; pdb.set_trace()

# Or use ipdb for better experience
import ipdb; ipdb.set_trace()

# Logging for debugging
import logging
logger = logging.getLogger(__name__)
logger.debug(f"Processing request: {request}")
```

### 3. Performance Profiling

```python
# Profile code performance
import cProfile
import pstats

def profile_function():
    pr = cProfile.Profile()
    pr.enable()
    
    # Your code here
    result = some_expensive_function()
    
    pr.disable()
    stats = pstats.Stats(pr)
    stats.sort_stats('cumulative')
    stats.print_stats()
    
    return result
```

## üé® UI/UX Contributions

### Desktop App Guidelines

1. **Consistent Design**
   - Follow existing UI patterns
   - Use consistent spacing and colors
   - Maintain accessibility standards

2. **User Experience**
   - Provide clear feedback for actions
   - Handle loading states gracefully
   - Show helpful error messages

3. **Testing UI Changes**
   ```bash
   cd desktop-app/electron-app
   npm run dev  # Test in development
   npm run build  # Test production build
   ```

## üìä Performance Contributions

### Optimization Areas

1. **Model Efficiency**
   - Quantization improvements
   - Memory usage optimization
   - Inference speed enhancements

2. **API Performance**
   - Caching strategies
   - Database query optimization
   - Response time improvements

3. **Desktop App Performance**
   - Bundle size reduction
   - Runtime performance
   - Memory usage optimization

## üîí Security Contributions

### Security Guidelines

1. **Input Validation**
   ```python
   from pydantic import BaseModel, validator
   
   class SecureRequest(BaseModel):
       prompt: str
       
       @validator('prompt')
       def validate_prompt(cls, v):
           # Add security validation
           if len(v) > 10000:
               raise ValueError('Prompt too long')
           return v
   ```

2. **Authentication & Authorization**
   ```python
   # Always verify tokens
   async def verify_request(request):
       token = request.headers.get('Authorization')
       if not token or not verify_token(token):
           raise HTTPException(status_code=401)
   ```

3. **Data Sanitization**
   ```python
   import re
   
   def sanitize_input(user_input: str) -> str:
       # Remove potentially dangerous content
       sanitized = re.sub(r'[<>"`]', '', user_input)
       return sanitized.strip()
   ```

## üåü Recognition and Community

### Contributor Recognition

- Contributors are recognized in README.md
- Significant contributions may be highlighted in releases
- Active contributors may be invited to join the maintainer team

### Community Guidelines

1. **Be Respectful**
   - Use welcoming and inclusive language
   - Respect different viewpoints and experiences
   - Accept constructive criticism gracefully

2. **Be Collaborative**
   - Help others learn and grow
   - Share knowledge and resources
   - Work together to solve problems

3. **Be Patient**
   - Remember that everyone is learning
   - Provide helpful feedback
   - Take time to explain complex concepts

## üìû Getting Help

### Communication Channels

- üêõ **Bug Reports**: GitHub Issues
- üí° **Feature Requests**: GitHub Issues
- ‚ùì **Questions**: GitHub Discussions
- üí¨ **Chat**: (Add Discord/Slack if available)

### Maintainer Contacts

- Create GitHub issues for technical questions
- Tag maintainers in discussions for urgent matters
- Use appropriate labels for different types of issues

## üìö Additional Resources

### Learning Resources

- [FastAPI Documentation](https://fastapi.tiangolo.com/)
- [LangChain Documentation](https://docs.langchain.com/)
- [Transformers Documentation](https://huggingface.co/docs/transformers/)
- [Electron Documentation](https://www.electronjs.org/docs/)

### Development Tools

- **VS Code Extensions**: Python, Pylance, Black, GitLens
- **Testing**: pytest, pytest-cov, pytest-asyncio
- **Linting**: flake8, mypy, black
- **Documentation**: Sphinx, mkdocs

---

Thank you for contributing to the Autonomous AI Agent project! üéâ

Your contributions help make this tool better for developers worldwide. Together, we're building the future of AI-assisted coding! üöÄ
